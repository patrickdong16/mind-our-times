# 当硅谷发现"大力出奇迹"不太灵了

Lex Fridman 最近请了两位嘉宾录了一期四个半小时的播客，聊 AI 的未来。四个半小时。这个时长本身就很能说明问题——在一个 15 秒短视频统治注意力的时代，有人觉得 AI 这个话题值得用小半个工作日来掰扯。

更有意思的是这两位嘉宾的身份：一位是大学教授，一位是研究员。不是 CEO，不是投资人，不是那些张口"改变世界"闭口"万亿市场"的人。Sebastian Raschka 写了本书教你从零搭大模型，Nathan Lambert 整天研究怎么让 AI 在强化学习里少犯蠢。换句话说，这俩人每天的工作是真的跟代码和论文打交道，而不是跟 PowerPoint 和 Term Sheet。

所以当他们说"规模法则正在失去吸引力"的时候，你最好竖起耳朵听听。

---

## 硅谷最昂贵的信仰危机

过去三年，AI 圈有一条不成文的信条：**模型越大，智商越高。** 这条信条简洁、优美、符合直觉，最重要的是——它让花大钱变得特别理直气壮。想要更聪明的 AI？给我十亿美元买 GPU。还不够聪明？再来十亿。

这套逻辑在 GPT-4 时代运转得非常流畅。每一代模型参数翻倍，能力也肉眼可见地提升。投资人欣慰，创始人得意，英伟达笑得合不拢嘴。然后 Claude Opus 4.5 来了，打了所有人一个耳光。

Anthropic 花了一笔据说非常恐怖的钱（具体数字没人敢说，但足够买下一支 NBA 球队的那种恐怖），训练了一个巨大无比的模型。结果呢？性能提升远不如 OpenAI 的 o1 ——而 o1 的秘诀不是更大的模型，而是让模型在回答问题时多"想一会儿"。

用 Raschka 的话说：**"规模法则没有死，只是其他方法现在更有吸引力了。"**

这句话翻译成人话就是：烧钱这条路走不太动了。

---

## 一道让 CFO 失眠的数学题

为什么"让模型多想一会儿"比"让模型更大"更划算？Nathan Lambert 给了一个堪称残忍的经济学解释：

> 如果你把钱砸进预训练，那是一次性买卖——训练完模型就永久拥有这个能力。但如果靠推理时间来提升表现，你是在每次用户提问时花钱。这就变成了一道数学题：我的模型能在市场上活多久？

这道题的答案正在变得越来越尴尬。

三年前，一个顶级模型的"货架期"可能是一两年。现在呢？六个月就算长的。今天你发布一个参数量惊人的大模型，半年后某个中国团队用十分之一的成本做出差不多的东西，你那笔"一次性投资"瞬间变成沉没成本。

所以 OpenAI 发布 GPT-5 的时候，选择了一个"相对较小"的模型配合强大的推理能力。不是他们不想堆参数，是账算不过来了。

这大概是科技史上最昂贵的信仰危机：当你发现"更大就是更好"不再成立的时候，你已经往这个方向砸了几百亿美元。

---

## DeepSeek 的"顿悟时刻"

2025 年 AI 领域最让人兴奋的故事，不是又有哪家公司融了几十亿，而是一个叫 RLVR 的训练方法被规模化应用。

RLVR 的全称是"强化学习验证奖励"，听起来很学术，但原理简单得令人发指：

1. 给模型一道数学题
2. 让它随便怎么解，中间过程不管
3. 只看最终答案对不对
4. 对了给奖励，错了拉倒

就这么简单。没有人类专家手把手教它怎么推理，没有精心设计的思维链模板。你只是告诉它"答案对了才有糖吃"，然后神奇的事情发生了——**模型自己"发明"了逐步推理。**

DeepSeek R1 的训练日志里记录了一个被整个 AI 圈疯狂转发的"aha moment"：模型在解题过程中突然停下来，说了句类似"啊，我做错了，让我再试一次"的话，然后自己纠正了错误。

没人教它这么做。它自己学会的。

Raschka 在自己的实验室复现了这个实验，结果令人瞠目：**用 RLVR 训练 Qwen 3，仅仅 50 步（几分钟时间），准确率就从 15% 跳到了 50%。**

这说明什么？模型脑子里的知识早就有了，只是被锁着。RLVR 做的事情，不是往脑子里塞东西，而是找到了开锁的钥匙。

---

## 数据：新时代的石油（这次是真的）

当"堆参数"这条路走不通的时候，竞争焦点转移到了一个更古老、更无聊、但更要命的战场：**数据。**

Nathan Lambert 说了句大实话：

> 如果你加入一个前沿实验室想搞出点名堂，最好的办法就是找到更好的新数据。搞花哨的算法创新，那是最性感的科学家梦想。但大部分实际贡献其实是"让数据更好"或者"让基础设施快 5%"。

这话听起来一点都不酷，但它是真的。

数据工程的复杂程度远超外界想象。这不是找个实习生去网上扒文章那么简单。实验室的实际操作是：从 GitHub、Stack Exchange、Reddit、Wikipedia 等不同来源各抽一小撮数据，用小模型在每种配比上训练一遍，测性能，然后用线性回归找"最优混合比例"。听起来很系统对吧？问题是——**如果你的评测标准变了，整套配比都得重来。**

OLMo 3 用更少的数据反而跑出了更好的成绩，秘诀就是为推理能力专门找了新数据源，重新调了配比。

顺便说一句，数据这个战场还藏着法律地雷。2025 年 Anthropic 在法庭上输了一场官司，要赔作者 15 亿美元——因为他们通过种子下载搞了一批书来训练模型。这场官司"来了又走"，但它定义了数据获取的边界。以后想这么干的公司，可能得先准备好诉讼基金。

这场数据竞赛正在重塑商业格局。大型企业——制药、法律、金融——坐拥海量专有数据，未来可能会从前沿实验室挖人，自己搞内部模型团队。Raschka 的预言是：**"我们现在看到的只是通用大模型。它们甚至还没触及为特定任务专门训练的模型能做到的事。"**

翻译：通用模型是开胃菜，垂直领域模型才是正餐。而正餐的关键原料是你手里有没有独家数据。

---

## 从"工具"到"打工人"

如果说规模法则的式微是 2025 年 AI 圈最大的认知颠覆，那么"智能体"（Agents）的崛起就是最大的商业机会。

传统 AI 是个问答机器：你问它问题，它给你答案。智能体不一样。它能自己规划任务步骤，调用外部工具，处理需要好几个小时才能完成的复杂任务，中途遇到问题还会主动问你。

换句话说，**它不是工具，而是某种程度上的打工人。**

当被问到 AGI 该怎么定义的时候，两位嘉宾给了一个务实到近乎无聊的答案：**能够替代大多数远程工作者的 AI 系统。** 注意，不是"超越人类智慧"，不是"拥有自我意识"，而是"能帮你回邮件、写代码、做表格"。

这个定义低调得几乎让人失望，但它指向了一个价值万亿的市场：知识工作者的成本有多高，这个市场就有多大。

---

## Claude Code：AI 用 AI 写 AI

Claude Code 是 Anthropic 推出的编程助手，它的能力已经到了一个让程序员五味杂陈的程度：

- 能理解整个代码库（不是一个文件，是整个项目）
- 能同时改好几个文件
- 改完自己跑测试验证
- 遇到问题会停下来问你

Nathan Lambert 透露了一个细节：**Claude Code 是用 Claude Code 自己写出来的。** Anthropic 的工程师已经在大规模使用自家工具处理训练和生产代码。据说他们在推理上花的钱，是普通用户每月 100-200 美元订阅费的 10 到 100 倍。

一项针对 791 名十年以上经验程序员的调研显示：

- 大多数人发布的代码中，**超过一半是 AI 生成的**
- **资深程序员比初级程序员更爱用 AI**
- 约 **80% 的人觉得用 AI 让工作变得更愉快了**

最后这条数据才是重点。资深程序员用 AI 比例更高，不是因为 AI 太弱菜只有老手能驾驭，而是因为老手更知道怎么审查 AI 的输出、怎么把 AI 当杠杆而不是拐杖。

Lambert 的预测是：**到今年年底，软件工程中自动化的比例会非常高。但分布式 ML 训练这种硬活儿还是很难。软件工程师的角色会更多转向系统设计和定义"我们要什么结果"。**

代码民工的好日子要到头了，系统架构师的春天来了——如果他们能学会跟 AI 协作的话。

---

## 智能体的阿喀琉斯之踵

说了这么多好的，该泼点冷水了。

**"计算机操作"（Computer Use）目前还是个未解之谜。** 2025 年 Claude 和 OpenAI 的 Operator 都展示了让 AI 直接操作电脑的能力——打开浏览器、填表单、点按钮。实际体验怎么样？Lambert 原话："都很糟糕。"

问题出在哪儿？Raschka 一针见血：

> 对于任意任务，你仍然需要指定你想让 LLM 做什么。如果它搞不定最终目标，你作为用户要怎么引导它到达一个它至少能尝试的起点？界面设计真的非常非常难。

翻译：AI 可能很聪明，但它不知道你到底想要什么。而你也不知道怎么告诉它。人机交互界面——这个听起来很古老的问题——可能成为智能体时代最大的瓶颈。

2025 年底有篇"递归语言模型"论文提出了一个思路：与其让 AI 在一个超长的上下文里一次性解决所有问题，不如把任务拆成小块，每块递归调用 AI 处理。这种方法的准确率竟然比暴力堆上下文还高。

这暗示了一个投资机会：**谁能解决"怎么告诉 AI 你想要什么"这个问题，谁就能拿下智能体市场的大头。** 而答案可能不是让 AI 更聪明，而是让任务分解和人机协作更优雅。

---

## 持续学习：真正的远程打工人需要会"涨记性"

还有一个更根本的问题：**AI 不会从日常工作中学习。**

人类员工入职第一天可能啥都不会，但三个月后他就知道老板的脾气、公司的潜规则、哪个代码库是雷区。AI 不行。你今天教它的东西，明天它就忘了（技术上说，它的权重没更新）。

这就是为什么"替代远程工作者"的 AGI 定义听起来简单，实现起来很难。远程工作者能被替代，不是因为他们会回邮件、写代码，而是因为他们会**根据反馈调整**。

Lambert 对这个问题比较乐观：

> 我个人更看好通过提供非常好的上下文来让语言模型发挥作用。很多人不向模型提供足够的背景信息，模型以前也不是设计来接受这么多上下文的。智能体模型刚刚起步。

这话的意思是：与其花大价钱更新模型权重（贵、慢、有遗忘风险），不如把更多精力放在"怎么把背景信息喂给模型"上。

某种程度上，这是在用架构设计绕过科学难题。很硅谷的思路。

---

## 开源之战：这不是技术问题，是地缘政治

Nathan Lambert 在 AI 政策圈有个外号，叫"开源布道者"。他发起了一个叫 ADAM 的项目（美国真正开放模型），目标是让美国也有自己的顶级开源大模型。

为什么这件事重要？因为截至 2025 年 7 月，**中国有四五个 DeepSeek 级别的开源模型，美国一个都没有。**

"开源模型将成为 AI 研究的引擎，"Lambert 说，"因为所有人都从那里起步。如果最好的开源模型都来自中国，全球的 AI 研究生态就会围绕中国模型构建。"

Meta 的 Llama 本来是美国开源的希望，但 Llama 4 的失败成了一个警示故事。Lambert 透露了内幕：

> 我认为它在内部政治斗争和激励错位中崩塌了。研究人员想要做最好的模型，但管理层只想证明他们在某些指标上做到了第一。

过度追求基准测试排名，忽视了开源的真正价值——让社区能用、能信、能改、能懂。Llama 4 在排行榜上可能好看，但作为开源项目，它没能赢得开发者的心。

这场开源之战有着深刻的战略意义。谁定义了基础模型，谁就定义了整个生态系统的发展方向。

---

## 文本扩散：下一个范式还是又一个泡沫？

Raschka 提到了一个值得关注的新方向：**文本扩散模型。**

传统大模型是"自回归"的——一个字一个字往外蹦。文本扩散模型不一样，它可以并行生成所有字符，类似图像生成 AI 的工作方式。

Google 宣布了 Gemini Diffusion，声称在质量相当的情况下，生成速度大幅提升。已经有代码创业公司在用文本扩散模型生成超长的代码 diff——因为用自回归模型要花好几分钟，而"用户产品里每多一秒就会流失大量用户"。

这不太可能取代自回归模型（那玩意儿在很多场景下还是最优解），但它会开辟新的应用场景：快速、便宜、大规模的文本生成。

又一个值得盯着的技术方向。

---

## 永久底层阶级：硅谷最新的末日神话

最后聊聊硅谷的气氛。

Lambert 提到了一个在 AI 圈流传的 meme，叫"永久底层阶级"：

> 2025 年下半年是在 AI 创业公司或模型中创造持久价值的唯一时机。如果你现在不上车，所有价值都会被巨头捕获，你将永远贫穷。

这种末日紧迫感正在驱动疯狂的工作强度。前沿实验室普遍 996——每天早九到晚九，每周六天。

Raschka 分享了一个细节：苹果为了在中国建供应链，工程师的工作强度大到公司不得不设立"拯救婚姻"项目。有人死于这种程度的压榨。现在 AI 领域正在复制这种动态。

Lambert 自己也承认：

> 我认为 AI 是泡沫，但目前还是建设性的泡沫。我担心的是它会变成投机性的金融泡沫。我们确实拥有非常强大的东西，科技公司都在集体以数百亿美元投资买入这个愿景。

区分"泡沫"的性质很重要。建设性的泡沫会留下基础设施（铁路泡沫留下了铁路，互联网泡沫留下了光纤）。投机性的泡沫只会留下烂账。

务实的观察者应该区分三件事：

- **已经能用的东西**：代码生成、数据分析、内容创作——都在变好
- **承诺中的东西**：完全自主的智能体、AGI——还需要突破
- **没人算过的成本**：精英人才的倦怠率，可能成为行业的隐性负债

---

## 那么，钱该往哪儿投？

几个可能有用的判断：

**算力投资还有空间吗？** 有，但方向在变。预训练 scaling 效率下降，推理 scaling 需求上升。关键变化是从计算密集型转向内存密集型。这对 NVIDIA 的产品路线图有影响——他们能不能跟上这个转向，决定了他们能不能继续躺赢。

**开源模型会逆袭吗？** 会，但主要不是商业逻辑，是战略逻辑。谁的开源模型被全球开发者用得最多，谁就定义研究方向。这个位置现在是中国的。

**智能体市场谁能赢？** 不是模型最强的人，是用户数据和反馈循环最强的人。Cursor 每 90 分钟根据用户真实反馈更新模型权重——这才是竞争优势。

**最值得盯着的技术方向？** RLVR（让模型自己学会推理）、文本扩散（并行生成）、以及永远不够性感但永远最重要的：数据工程。

---

*本文基于 Lex Fridman Podcast 第 472 期编译整理。原节目时长 4 小时 25 分钟，如果你有小半天时间可以挥霍，[这里是 YouTube 链接](https://www.youtube.com/watch?v=EV7WhVT270Q)。*
