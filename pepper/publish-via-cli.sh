#!/bin/bash
# é€šè¿‡CloudBase CLIè°ƒç”¨äº‘å‡½æ•°å‘å¸ƒæ–‡ç« 

DATE=$1
if [ -z "$DATE" ]; then
  echo "ç”¨æ³•: ./publish-via-cli.sh YYYY-MM-DD"
  exit 1
fi

FULLDATA="/Users/dq/.openclaw/workspace/memory/briefing-index/${DATE}-full.json"
if [ ! -f "$FULLDATA" ]; then
  echo "âœ— æ–‡ä»¶ä¸å­˜åœ¨: $FULLDATA"
  exit 1
fi

# è½¬æ¢æ ¼å¼å¹¶ç”Ÿæˆä¸´æ—¶JSON
TEMP_JSON="/tmp/mot-publish-${DATE}.json"
python3 << 'PYEOF' > "$TEMP_JSON"
import sys
import json

date = sys.argv[1]
input_file = f"/Users/dq/.openclaw/workspace/memory/briefing-index/{date}-full.json"

# é¢†åŸŸæ˜ å°„
DOMAIN_MAP = {
    "æŠ€æœ¯": "T", "AI": "T", "ç§‘æŠ€": "T",
    "æ”¿æ²»": "P", "åœ°ç¼˜æ”¿æ²»": "P", "æ”¿ç­–": "P",
    "å†å²": "H",
    "å“²å­¦": "Î¦", "æ€æƒ³": "Î¦",
    "å®—æ•™": "R",
    "é‡‘è": "F", "ç»æµ": "F",
}

def map_domain(d):
    for k, v in DOMAIN_MAP.items():
        if k in d:
            return v
    return "Î¦"

def shorten_bio(bio, max_len=50):
    if len(bio) <= max_len:
        return bio
    first = bio.split("ã€‚")[0]
    if len(first) <= max_len:
        return first
    return bio[:max_len] + "..."

def clean_insight(s):
    return s.replace("ğŸ’­ é¢˜å¤–è¯ï¼š", "").replace("ğŸ’­é¢˜å¤–è¯ï¼š", "").replace("ğŸ’­ ", "")

with open(input_file, "r") as f:
    data = json.load(f)

articles = []
for item in data:
    articles.append({
        "domain": map_domain(item["domain"]),
        "title": item["title"],
        "author_name": item["author"],
        "author_intro": shorten_bio(item["author_bio"]),
        "source": item["source"],
        "source_url": item["url"],
        "content": item["summary"],
        "insight": clean_insight(item["signal"])
    })

payload = {"date": date, "articles": articles}
print(json.dumps(payload, ensure_ascii=False))
PYEOF

python3 "$TEMP_JSON" "$DATE"

# è°ƒç”¨äº‘å‡½æ•°
echo ""
echo "æ­£åœ¨å‘å¸ƒ $DATE çš„æ–‡ç« åˆ° CloudBase..."
cloudbase functions:invoke articles-write \
  --params "$(cat $TEMP_JSON)" \
  -e mind-our-times-3g7c3va270081e5c

# æ¸…ç†
rm -f "$TEMP_JSON"
